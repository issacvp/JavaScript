Learning Ojectives :
=====================
Describe the motivation of using Big O notation 
Explore the rules for simplifying Big O 
Walkthrough how to derive the complexity of code snippets 

why do we use Big O?
 Any give n problem has many solutions ,  Big O is help to understand the best solution 
 Resources : 
    Time (duration)
    Space  (Memory) 

The solution L 
. BigO notation can objectivel describe the efficently of code without the use of concrete units 
.Focus on how the time and space requireents scale 
Prepare for the worst scenario 


======================================================
            Simplifying Big 0 : 
======================================================
1) Product Rule 
    IF the Big O is the product of numlitple terms , drop the contant terms 
    O(4*n) ==> O(n)
    O(512*n) ==> O(n)
    O(n/3) ==> O(n* 1/3) ==> O(n)
    O(5*n*) ==> O(n*n) ==> O(n^2)
    O(765) ==> O(1) 

2) Sum Rule 
    If the Big O is the sum of multiple teerms only keep the largst sums 
    O(n+10000) ==> O(n)   n > 10000
    O(n^2+n) ==> O(n^2)   n^2 > n 
    O(n+500 +n^3+n^2) ==> O(n^3)  n^2

Apply the product rule followed by sum rule 
    O(5n^2 +100n +17) 
        ==> O(n^2 + n + 1)
        ==> O(n^2)
    O((n/3)^6+10n)
        ==> O(n^6+n)
        ==> O(n^6)

Analyzing Recursive Code : 
    Our space complexity should consider the space taken by recursive calls on the call stack 


We use Bog O to compare solutions by how they sacel wiwth the size of the input 
Production and Sum somplification rules 




=============================================================
                  Big O complexity classes 
============================================================
. Explore the 7 common complexity classes 
. Analyze functions with multiple arguments 
. Visualize the space 


==================
1) Constant O(1) 
==================
The number of steps deoes not depend on the input size 

==================
2) Logarithms  O(log(n)) 
==================
A log is the opposite of exponent 
An exponent is a repeated multiplication , a log is repeated division 
if 2^5 = 32 ,  log(32) = 5 
 
function fun(n) {
    while (n>=1) {
        console.log(n);
        n/=2;
    }
    console.log("done");
};

fun(32) 
32
16
8
4
2
done


function  foo(n) {
    if (n <=1) {
        console.log("hooray");
        return;
    }
    console.log(n);
    foo(n/2);
}

foo(30) ;
30
15
7.2
3.75


=====================
3) Linear  O(n)
==================
function foo(array) {
    for ( let i of array){
        console.log(i);
    }
};

foo(['soho',]);

function bar (n) {
    if(n===0) return;
    console.log(n);
    bar(n-1);
};

bar(5);
5
4
3
2
1

==========================
4) Loglinear O(n*log(n))  
==========================
Has linear behaviour nested in log steps 
Bigger than O(n) bur smaller than O(n^2) 


funtion bar(str) {
    console.log(str);
    if(str.length <= 1) return;
    const midTdx = Math.floor(str.length / 2 );
    bar(str.slice(0,midTdx));
};


Recursion --> O(log(n))  String is divided to half each time 
 str.slice() --> It gives a new copy of the actual string which need to run to half of the string  --> n 

O(n*log(n))


function foo(array) {
    let str = "";
    for(let i of array) {                                 <--- O(n)
        str += i;
    }
    if(array.length <=1) return;
    const midTdx = Math.floor(array.length / 2 );
    foo(array.slice(0,midTdx));                           <--- O(n) 
    foo(array.slice(midTdx));                             <--- O(n)
}


Its a tree, with height as log(n) , n unit of work 

O(n*log(n))

==================
5) Polynomial O(n^c) 
========================

n is the size of the input 
C is some constant 
includes O(n^2) quadratic, O(n^3) , cubic etc 


function foo (array ) {
    for(let i of array) {
        for(let j of array) {
            console.log(i + "/" j);
        }
    }
};


function bar (str) {
    if(str.length === 0) return;
    const firstChar = str[0];
    const rest = str.slice(1);       <====== slice O(n)
    console.log(firstChar) ;
    bar(rest);                       <====== Recursion O(n)
}


==================
6) Exponential O(2^n) 
========================


const foo = () => {
    if(n===1) return ; 
    foo(n-1);
    foo(n-1);
}

O(2^n) complexity 

const bar = () => {
    if ( n===1 ) return ; 
    bar(n-1);
    bar(n-1);
    bar(n-1);
} 

O(3^n) complexity 


========================
7) Factorial O(n!) 
========================

const foo = () => {
    if(n==1) return; 
    for(let i=0; i<n;i++){
        foo(n-1);
    }
};


Analyzing functions with multiple arguments 
--------------------------------------------
 function foo (m,n ) {
     for( let i =0; i< m; i++){
         console.log("hi)
     }
     for(let j =0; j <n; j++) {
         console.log("hello");
     }

 }

 O(m+n)

 function crossPairs(array1, array2) {
     for(let i of array1) {
         for(let j of array2) {
             console.log(i,j);
         }
     }
 }

 O(m*n)

 function foo(str1, str2) {
     if(str1.length > str2.length) {
         for(let i=0; i<str1.length;i++){
             console.log(str1[i]);
         }
     } else {
         for(let j=0; i<str2.length;j++){
             console.log(str2[j];
         }
     }
 };

This can represent in two ways 
 O(max(m,n))   where m,n are the strength lengths
 O(n), wehre n is the length of the longer strengths 


 Analyzing stack space for Recurstion 
 ========================
The space required on the call stack is the max stack depth 
const bar = () => {
    if(n===0) returrn;
    bar(n-1);
    bar(n-1);
}

complexity : 
    Time : O(2^n) 
    Space : O(n)   <-- Because at any point in time, max n things in the stack 
    